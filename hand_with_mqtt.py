import cv2
import mediapipe as mp
import numpy as np
import threading
from PIL import ImageFont, ImageDraw, Image
import time
import json
import os

from Mqtt_test import mqtt_publisher, mqtt_subscriber

# åˆå§‹åŒ– MediaPipe
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
mp_draw = mp.solutions.drawing_utils

# åŠ è¼‰ä¸­æ–‡å­—å‹
try:
    font_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "ä¸­æ–‡å­—é«”", "NotoSansTC-VariableFont_wght.ttf")
    font = ImageFont.truetype(font_path, 16)  # é€²ä¸€æ­¥æ¸›å°å­—å‹å¤§å°
except Exception as e:
    print(f"ç„¡æ³•è¼‰å…¥å­—é«”: {str(e)}")
    print("ä½¿ç”¨é è¨­å­—é«”")
    font = ImageFont.load_default()

# è¨ˆç®—å¤¾è§’
def calculate_angle(a, b, c):
    """ è¨ˆç®— B é»ç‚ºä¸­å¿ƒï¼Œå‘é‡ BA å’Œ BC ä¹‹é–“çš„å¤¾è§’ """
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)

    ba = a - b
    bc = c - b

    cos_theta = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # é¿å…æ•¸å€¼èª¤å·®
    return np.degrees(angle)

def hand_camera():
    # å–å¾—æ”å½±æ©Ÿç•«é¢
    cap = cv2.VideoCapture(0)
    
    # è¨­ç½®æœ€ä½çš„è§£æåº¦
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 160)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 120)
    
    # è¨­ç½®æœ€ä½çš„å¹€ç‡
    cap.set(cv2.CAP_PROP_FPS, 5)
    
    # åˆå§‹åŒ–è®Šæ•¸
    last_time = time.time()
    frame_count = 0
    fps = 0
    last_mqtt_time = time.time()
    mqtt_interval = 2.0  # ä¿®æ”¹ç‚ºæ¯å…©ç§’å‚³é€ä¸€æ¬¡
    last_hand_time = time.time()
    hand_interval = 0.1  # æ‰‹éƒ¨è¿½è¹¤æ›´æ–°é–“éš”
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # è¨ˆç®— FPS
        frame_count += 1
        current_time = time.time()
        if current_time - last_time >= 1.0:
            fps = frame_count
            frame_count = 0
            last_time = current_time
        
        # åªåœ¨ç‰¹å®šæ™‚é–“é–“éš”é€²è¡Œæ‰‹éƒ¨è¿½è¹¤
        if current_time - last_hand_time >= hand_interval:
            # è½‰æ› BGR åˆ° RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result = hands.process(frame_rgb)
            
            if result.multi_hand_landmarks:
                for hand_landmarks in result.multi_hand_landmarks:
                    mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                    
                    landmarks = hand_landmarks.landmark
                    
                    fingers = {
                        "æ‹‡æŒ‡": [1, 2, 3, 4],
                        "é£ŸæŒ‡": [5, 6, 7, 8],
                        "ä¸­æŒ‡": [9, 10, 11, 12],
                        "ç„¡åæŒ‡": [13, 14, 15, 16],
                        "å°æŒ‡": [17, 18, 19, 20]
                    }
                    
                    angles = {}
                    y_offset = 30  # èª¿æ•´æ–‡å­—èµ·å§‹ä½ç½®
                    
                    for name, indices in fingers.items():
                        mcp = [landmarks[indices[0]].x, landmarks[indices[0]].y, landmarks[indices[0]].z]
                        pip = [landmarks[indices[1]].x, landmarks[indices[1]].y, landmarks[indices[1]].z]
                        dip = [landmarks[indices[2]].x, landmarks[indices[2]].y, landmarks[indices[2]].z]
                        tip = [landmarks[indices[3]].x, landmarks[indices[3]].y, landmarks[indices[3]].z]
                        
                        pip_angle = calculate_angle(mcp, pip, dip)
                        dip_angle = calculate_angle(pip, dip, tip)
                        total_angle = pip_angle + dip_angle
                        
                        angles[name] = (pip_angle, dip_angle, total_angle)
                    
                    # ç¹ªè£½ä¸­æ–‡å­—
                    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(img_pil)
                    
                    # é¡¯ç¤º FPS å’Œæ•ˆèƒ½è³‡è¨Š
                    draw.text((2, 2), f"FPS: {fps}", font=font, fill=(255, 255, 0))
                    draw.text((2, 20), f"Res: 160x120", font=font, fill=(255, 255, 0))
                    
                    for name, (pip_angle, dip_angle, total_angle) in angles.items():
                        text = f"{name} PIP:{int(pip_angle)}Â° DIP:{int(dip_angle)}Â° ç¸½è¨ˆ:{int(180-(360-total_angle))}Â°"
                        draw.text((2, y_offset), text, font=font, fill=(255, 255, 0))
                        y_offset += 20  # æ¸›å°è¡Œé–“è·
                    
                    # åªåœ¨ç‰¹å®šæ™‚é–“é–“éš”ç™¼é€ MQTT æ¶ˆæ¯
                    if current_time - last_mqtt_time >= mqtt_interval:
                        # å»ºç«‹åŒ…å«æ‰€æœ‰æ‰‹æŒ‡æ•¸æ“šçš„å­—å…¸
                        all_fingers_data = {
                            "timestamp": time.time(),
                            "fingers": []
                        }
                        
                        for name, (pip_angle, dip_angle, total_angle) in angles.items():
                            finger_data = {
                                "name": name,
                                "pip_angle": float(pip_angle),
                                "dip_angle": float(dip_angle),
                                "total_angle": float(total_angle)
                            }
                            all_fingers_data["fingers"].append(finger_data)
                        
                        # å°‡æ‰€æœ‰æ‰‹æŒ‡æ•¸æ“šè½‰æ›ç‚º JSON ä¸¦ç™¼é€
                        data_str = json.dumps(all_fingers_data)
                        mqtt_publisher(data_str)
                        print(f"ğŸ“¨ ç™¼é€æ‰‹éƒ¨æ•¸æ“š (æ™‚é–“: {time.strftime('%H:%M:%S', time.localtime(time.time()))})")
                        last_mqtt_time = current_time
                    
                    frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
            
            last_hand_time = current_time
        
        cv2.imshow("Hand Tracking", frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    try:
        # å•Ÿå‹• MQTT è¨‚é–±è€…ç·šç¨‹
        subscriber_thread = threading.Thread(target=mqtt_subscriber)
        subscriber_thread.daemon = True
        subscriber_thread.start()

        # å•Ÿå‹•ä¸»ç¨‹åº
        hand_camera()
    except KeyboardInterrupt:
        print("\nç¨‹å¼çµæŸ")
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    finally:
        cv2.destroyAllWindows()
    
