import cv2
import mediapipe as mp
import numpy as np
import threading
from PIL import ImageFont, ImageDraw, Image
import time
import json
import os
import logging
import base64
from Mqtt import mqtt_publisher, mqtt_subscriber

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ‰‹æ©Ÿæ”åƒé ­è¨­ç½®
MOBILE_CAMERA_IP = "10.219.83.13"  # æ‰‹æ©Ÿ IP åœ°å€
MOBILE_CAMERA_PORT = 8080  # IP Webcam çš„é è¨­ç«¯å£
MOBILE_CAMERA_URL = f"http://{MOBILE_CAMERA_IP}:{MOBILE_CAMERA_PORT}/video"  # ä½¿ç”¨ /video URL

# è¨­ç½®æ”åƒé ­åƒæ•¸ï¼ˆæ ¹æ“šæ¸¬è©¦çµæœï¼‰
CAMERA_WIDTH = 640  # æ¸›å°è§£æåº¦ä»¥æé«˜æ€§èƒ½
CAMERA_HEIGHT = 480
CAMERA_FPS = 30

# ä½¿ç”¨é è¨­å­—é«”
font = ImageFont.load_default()

# åˆå§‹åŒ– MediaPipe
try:
    # è¨­ç½® MediaPipe åƒæ•¸
    mp_hands = mp.solutions.hands
    hands = mp_hands.Hands(
        static_image_mode=False,
        max_num_hands=2,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    mp_draw = mp.solutions.drawing_utils
    
    # ç­‰å¾… MediaPipe åˆå§‹åŒ–å®Œæˆ
    time.sleep(2)
    
    logger.info("MediaPipe åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    logger.error(f"åˆå§‹åŒ– MediaPipe æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    raise

# è¨ˆç®—è§’åº¦çš„å‡½æ•¸
def calculate_angle(a, b, c):
    """è¨ˆç®—ä¸‰é»ä¹‹é–“çš„è§’åº¦ï¼ˆ2Dï¼‰
    
    Args:
        a: é» A çš„åº§æ¨™ (x, y)
        b: é» B çš„åº§æ¨™ (x, y) - ä¸­é–“é»
        c: é» C çš„åº§æ¨™ (x, y)
    
    Returns:
        float: è§’åº¦ï¼ˆåº¦æ•¸ï¼‰
    """
    # è¨ˆç®—å‘é‡
    ba = np.array(b) - np.array(a)
    bc = np.array(c) - np.array(b)
    
    # è¨ˆç®—é¤˜å¼¦å€¼
    cos_theta = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    
    # è¨ˆç®—è§’åº¦ä¸¦è½‰æ›ç‚ºåº¦æ•¸
    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # é¿å…æ•¸å€¼èª¤å·®
    return np.degrees(angle)

def init_camera():
    """Initialize camera"""
    print(f"Connecting to mobile camera: {MOBILE_CAMERA_URL}")
    
    # Only use mobile camera
    cap = cv2.VideoCapture(MOBILE_CAMERA_URL)
    if not cap.isOpened():
        print(f"âŒ Failed to connect to mobile camera ({MOBILE_CAMERA_URL})")
        return None
    
    print(f"âœ… Successfully connected to mobile camera ({MOBILE_CAMERA_URL})")
    
    # Set camera parameters
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    cap.set(cv2.CAP_PROP_FPS, CAMERA_FPS)
    
    # Check if parameters are set successfully
    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    fps = cap.get(cv2.CAP_PROP_FPS)
    print(f"Parameters after setting - Width: {width}, Height: {height}, FPS: {fps}")

    return cap

# ä¸»ç¨‹åºå‡½æ•¸
def hand_camera():
    # åˆå§‹åŒ–æ”åƒé ­
    cap = init_camera()
    if cap is None:
        logger.error("ç„¡æ³•åˆå§‹åŒ–æ”åƒé ­")
        return
    
    # åˆå§‹åŒ–è®Šæ•¸
    last_time = time.time()
    frame_count = 0
    fps = 0
    last_mqtt_time = time.time()
    mqtt_interval = 2.0  # æ¯å…©ç§’å‚³é€ä¸€æ¬¡
    last_hand_time = time.time()
    hand_interval = 0.1  # æ‰‹éƒ¨è¿½è¹¤æ›´æ–°é–“éš”
    
    while True:
        try:
            ret, frame = cap.read()
            if not ret:
                logger.error("ç„¡æ³•è®€å–æ”åƒé ­ç•«é¢")
                break
            
            # è¨ˆç®— FPS
            frame_count += 1
            current_time = time.time()
            if current_time - last_time >= 1.0:
                fps = frame_count
                frame_count = 0
                last_time = current_time
            
            # åªåœ¨ç‰¹å®šæ™‚é–“é–“éš”é€²è¡Œæ‰‹éƒ¨è¿½è¹¤
            if current_time - last_hand_time >= hand_interval:
                # è½‰æ› BGR åˆ° RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                result = hands.process(frame_rgb)
                
                if result.multi_hand_landmarks:
                    for hand_landmarks in result.multi_hand_landmarks:
                        mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                        
                        landmarks = hand_landmarks.landmark
                        
                        fingers = {
                            "æ‹‡æŒ‡": [1, 2, 3, 4],
                            "é£ŸæŒ‡": [5, 6, 7, 8],
                            "ä¸­æŒ‡": [9, 10, 11, 12],
                            "ç„¡åæŒ‡": [13, 14, 15, 16],
                            "å°æŒ‡": [17, 18, 19, 20]
                        }
                        
                        angles = {}
                        y_offset = 30  # èª¿æ•´æ–‡å­—èµ·å§‹ä½ç½®
                        
                        for name, indices in fingers.items():
                            # å–å¾—é—œç¯€åº§æ¨™ï¼Œä¸¦è½‰æ›ç‚ºç›¸å°åº§æ¨™
                            mcp = [landmarks[indices[0]].x * frame.shape[1], landmarks[indices[0]].y * frame.shape[0]]
                            pip = [landmarks[indices[1]].x * frame.shape[1], landmarks[indices[1]].y * frame.shape[0]]
                            dip = [landmarks[indices[2]].x * frame.shape[1], landmarks[indices[2]].y * frame.shape[0]]
                            tip = [landmarks[indices[3]].x * frame.shape[1], landmarks[indices[3]].y * frame.shape[0]]
                            
                            # è¨ˆç®—è§’åº¦
                            pip_angle = calculate_angle(mcp, pip, dip)
                            dip_angle = calculate_angle(pip, dip, tip)
                            
                            # ç¢ºä¿è§’åº¦åœ¨åˆç†ç¯„åœå…§
                            pip_angle = min(max(pip_angle, 0), 180)
                            dip_angle = min(max(dip_angle, 0), 180)
                            
                            # è¨ˆç®—ç¸½è§’åº¦
                            total_angle = pip_angle + dip_angle
                            if total_angle > 180:
                                total_angle = 180
                            
                            angles[name] = (pip_angle, dip_angle, total_angle)
                        
                        # ç¹ªè£½ä¸­æ–‡å­—
                        img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                        draw = ImageDraw.Draw(img_pil)
                        
                        # é¡¯ç¤º FPS å’Œæ•ˆèƒ½è³‡è¨Š
                        draw.text((2, 2), f"FPS: {fps}", font=font, fill=(255, 255, 0))
                        draw.text((2, 20), f"Res: {CAMERA_WIDTH}x{CAMERA_HEIGHT}", font=font, fill=(255, 255, 0))
                        
                        for name, (pip_angle, dip_angle, total_angle) in angles.items():
                            text = f"{name} PIP:{int(pip_angle)}Â° DIP:{int(dip_angle)}Â° ç¸½è¨ˆ:{int(180-(360-total_angle))}Â°"
                            draw.text((2, y_offset), text, font=font, fill=(255, 255, 0))
                            y_offset += 20  # æ¸›å°è¡Œé–“è·
                        
                        # åªåœ¨ç‰¹å®šæ™‚é–“é–“éš”ç™¼é€ MQTT æ¶ˆæ¯
                        if current_time - last_mqtt_time >= mqtt_interval:
                            # å»ºç«‹åŒ…å«æ‰€æœ‰æ‰‹æŒ‡æ•¸æ“šçš„å­—å…¸
                            all_fingers_data = {
                                "timestamp": time.time(),
                                "fingers": []
                            }
                            
                            for name, (pip_angle, dip_angle, total_angle) in angles.items():
                                finger_data = {
                                    "name": name,
                                    "pip_angle": float(pip_angle),
                                    "dip_angle": float(dip_angle),
                                    "total_angle": float(total_angle)
                                }
                                all_fingers_data["fingers"].append(finger_data)
                            
                            # å°‡æ‰€æœ‰æ‰‹æŒ‡æ•¸æ“šè½‰æ›ç‚º JSON ä¸¦ç™¼é€
                            try:
                                data_str = json.dumps(all_fingers_data)
                                mqtt_publisher(data_str)
                                print(f"ğŸ“¨ ç™¼é€æ‰‹éƒ¨æ•¸æ“š (æ™‚é–“: {time.strftime('%H:%M:%S', time.localtime(time.time()))})")
                            except Exception as e:
                                logger.error(f"ç™¼é€ MQTT æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                                logger.error(f"æ•¸æ“šæ ¼å¼: {data_str}")
                            last_mqtt_time = current_time
                        
                        frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
                
                last_hand_time = current_time
            
            # é¡¯ç¤ºè¦–é »å¹€
            cv2.imshow("Hand Tracking", frame)
            
            # æª¢æŸ¥é€€å‡ºæ¢ä»¶
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
            
        except Exception as e:
            logger.error(f"è™•ç†æ”åƒé ­ç•«é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            break
    
    # æ¸…ç†è³‡æº
    cap.release()
    cv2.destroyAllWindows()

def init_camera():
    """Initialize camera"""
    print(f"Connecting to mobile camera: {MOBILE_CAMERA_URL}")
    
    # Only use mobile camera
    cap = cv2.VideoCapture(MOBILE_CAMERA_URL)
    if not cap.isOpened():
        print(f"âŒ Failed to connect to mobile camera ({MOBILE_CAMERA_URL})")
        return None
    
    print(f"âœ… Successfully connected to mobile camera ({MOBILE_CAMERA_URL})")
    
    # Set camera parameters
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    cap.set(cv2.CAP_PROP_FPS, CAMERA_FPS)
    
    # Check if parameters are set successfully
    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    fps = cap.get(cv2.CAP_PROP_FPS)
    print(f"Parameters after setting - Width: {width}, Height: {height}, FPS: {fps}")

    return cap

# ä¸»ç¨‹åºå‡½æ•¸
def hand_camera():
    # åˆå§‹åŒ–æ”åƒé ­
    cap = init_camera()
    if cap is None:
        print("âŒ ç„¡æ³•åˆå§‹åŒ–æ”åƒé ­")
        return
    
# ä¸éœ€è¦é‡è¤‡è¨­ç½®ç›¸æ©Ÿåƒæ•¸ï¼Œå› ç‚ºå·²ç¶“åœ¨ init_camera() ä¸­è¨­ç½®éäº†
    # ä½¿ç”¨ init_camera() ä¸­è¨­ç½®çš„è§£æåº¦å’Œå¹€ç‡
    
    # åˆå§‹åŒ–è®Šæ•¸
    last_time = time.time()
    frame_count = 0
    fps = 0
    last_mqtt_time = time.time()
    mqtt_interval = 2.0  # æ¯å…©ç§’å‚³é€ä¸€æ¬¡
    last_hand_time = time.time()
    hand_interval = 0.3  # å¢åŠ æ‰‹éƒ¨è¿½è¹¤æ›´æ–°é–“éš”åˆ°0.3ç§’
    last_angles = {}  # ç”¨æ–¼å­˜å„²ä¸Šä¸€å¹€çš„è§’åº¦
    angle_smoothing = 0.3  # è§’åº¦å¹³æ»‘åƒæ•¸ï¼ˆ0.0-1.0ï¼‰
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # è¨ˆç®— FPS
        frame_count += 1
        current_time = time.time()
        if current_time - last_time >= 1.0:
            fps = frame_count
            frame_count = 0
            last_time = current_time
        
        # åªåœ¨ç‰¹å®šæ™‚é–“é–“éš”é€²è¡Œæ‰‹éƒ¨è¿½è¹¤
        if current_time - last_hand_time >= hand_interval:
            # è½‰æ› BGR åˆ° RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result = hands.process(frame_rgb)
            
            if result.multi_hand_landmarks:
                for hand_landmarks in result.multi_hand_landmarks:
                    mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                    
                    landmarks = hand_landmarks.landmark
                    
                    # ä½¿ç”¨æ•¸å­—ç·¨ç¢¼æ›¿ä»£ä¸­æ–‡å­—ç¬¦
                    fingers = {
                        0: [1, 2, 3, 4],    # æ‹‡æŒ‡
                        1: [5, 6, 7, 8],    # é£ŸæŒ‡
                        2: [9, 10, 11, 12], # ä¸­æŒ‡
                        3: [13, 14, 15, 16],# ç„¡åæŒ‡
                        4: [17, 18, 19, 20] # å°æŒ‡
                    }
                    
                    angles = {}
                    y_offset = 30  # èª¿æ•´æ–‡å­—èµ·å§‹ä½ç½®
                    
                    for name, indices in fingers.items():
                        # å–å¾—é—œç¯€åº§æ¨™ï¼Œåªä½¿ç”¨ x, y åº§æ¨™
                        mcp = [landmarks[indices[0]].x, landmarks[indices[0]].y]
                        pip = [landmarks[indices[1]].x, landmarks[indices[1]].y]
                        dip = [landmarks[indices[2]].x, landmarks[indices[2]].y]
                        tip = [landmarks[indices[3]].x, landmarks[indices[3]].y]
                        
                        # è¨ˆç®—è§’åº¦
                        pip_angle = calculate_angle(mcp, pip, dip)
                        dip_angle = calculate_angle(pip, dip, tip)
                        
                        # è¨ˆç®—ç¸½è§’åº¦
                        total_angle = pip_angle + dip_angle
                        if total_angle > 180:
                            total_angle = 180
                        
                        # å¦‚æœæœ‰ä¸Šä¸€å¹€çš„è§’åº¦ï¼Œé€²è¡Œå¹³æ»‘è™•ç†
                        if name in last_angles:
                            last_pip, last_dip, last_total = last_angles[name]
                            pip_angle = pip_angle * angle_smoothing + last_pip * (1 - angle_smoothing)
                            dip_angle = dip_angle * angle_smoothing + last_dip * (1 - angle_smoothing)
                            total_angle = total_angle * angle_smoothing + last_total * (1 - angle_smoothing)
                        
                        angles[name] = (pip_angle, dip_angle, total_angle)
                        last_angles[name] = angles[name]
                    
                    # ç¹ªè£½ä¸­æ–‡å­—
                    img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(img_pil)
                    
                    # é¡¯ç¤º FPS å’Œæ•ˆèƒ½è³‡è¨Š
                    draw.text((2, 2), f"FPS: {fps}", font=font, fill=(255, 255, 0))
                    # é¡¯ç¤ºè§£æåº¦å’Œå¹€ç‡
                    draw.text((2, 20), f"Res: {frame.shape[1]}x{frame.shape[0]}", font=font, fill=(255, 255, 0))
                    draw.text((2, 40), f"FPS: {fps}", font=font, fill=(255, 255, 0))
                    
                    # åœ¨é¡¯ç¤ºæ™‚å°‡æ•¸å­—è½‰æ›å›ä¸­æ–‡å­—ç¬¦
                    finger_names = ["æ‹‡æŒ‡", "é£ŸæŒ‡", "ä¸­æŒ‡", "ç„¡åæŒ‡", "å°æŒ‡"]
                    for idx, (pip_angle, dip_angle, total_angle) in angles.items():
                        name = finger_names[idx]
                        text = f"{name} PIP:{int(pip_angle)}Â° DIP:{int(dip_angle)}Â° ç¸½è¨ˆ:{int(total_angle)}Â°"
                        draw.text((2, y_offset), text, font=font, fill=(255, 255, 0))
                        y_offset += 20  # æ¸›å°è¡Œé–“è·
                    
                    # åªåœ¨ç‰¹å®šæ™‚é–“é–“éš”ç™¼é€ MQTT æ¶ˆæ¯
                    if current_time - last_mqtt_time >= mqtt_interval:
                        # å»ºç«‹åŒ…å«æ‰€æœ‰æ‰‹æŒ‡æ•¸æ“šçš„å­—å…¸
                        all_fingers_data = {
                            "timestamp": time.time(),
                            "fingers": []
                        }
                        
                        for name, (pip_angle, dip_angle, total_angle) in angles.items():
                            # ä½¿ç”¨æ•¸å­—ç·¨ç¢¼æ›¿ä»£ä¸­æ–‡å­—ç¬¦
                            finger_data = {
                                "finger_id": idx,
                                "pip_angle": float(pip_angle),
                                "dip_angle": float(dip_angle),
                                "total_angle": float(total_angle)
                            }
                            all_fingers_data["fingers"].append(finger_data)
                        
                        # å°‡æ‰€æœ‰æ‰‹æŒ‡æ•¸æ“šè½‰æ›ç‚º JSON ä¸¦ç™¼é€
                        data_str = json.dumps(all_fingers_data)
                        mqtt_publisher(data_str)
                        print(f"ğŸ“¨ ç™¼é€æ‰‹éƒ¨æ•¸æ“š (æ™‚é–“: {time.strftime('%H:%M:%S', time.localtime(time.time()))})")
                        last_mqtt_time = current_time
                    
                    frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
            
            last_hand_time = current_time
        
        cv2.imshow("Hand Tracking", frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    try:
        # å•Ÿå‹• MQTT è¨‚é–±è€…ç·šç¨‹
        subscriber_thread = threading.Thread(target=mqtt_subscriber)
        subscriber_thread.daemon = True
        subscriber_thread.start()

        # å•Ÿå‹•ä¸»ç¨‹åº
        hand_camera()
    except KeyboardInterrupt:
        print("\nç¨‹å¼çµæŸ")
    except Exception as e:
        print(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
    finally:
        cv2.destroyAllWindows()
